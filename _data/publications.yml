main:

  - title: "Deep Learning for Image Super-Resolution"
    authors: Yixiao Zhang, Xinyi Li, Huimiao Chen, Alan L. Yuille, <strong>Yaoyao Liu*</strong>, Zongwei Zhou⋆
    conference: International Conference on Medical Image Computing and Computer-Assisted Intervention <strong>(MICCAI)</strong>, 2023.
    pdf: /Continual Learning for Abdominal Multi-Organ.pdf
    abstract: >
      The ability to dynamically extend a model to new data and classes is critical for multiple organ and tumor segmentation. However, due to privacy regulations, accessing previous data and annotations can
      be problematic in the medical domain. This poses a significant barrier
      to preserving the high segmentation accuracy of the old classes when
      learning from new classes because of the catastrophic forgetting problem. In this paper, we first empirically demonstrate that simply using
      high-quality pseudo labels can fairly mitigate this problem in the setting of organ segmentation. Furthermore, we put forward an innovative architecture designed specifically for continuous organ and tumor
      segmentation, which incurs minimal computational overhead. Our proposed design involves replacing the conventional output layer with a
      suite of lightweight, class-specific heads, thereby offering the flexibility
      to accommodate newly emerging classes. These heads enable independent predictions for newly introduced and previously learned classes,
      effectively minimizing the impact of new classes on old ones during
      the course of continual learning. We further propose incorporating Contrastive Language–Image Pretraining (CLIP) embeddings into the organspecific heads. These embeddings encapsulate the semantic information
      of each class, informed by extensive image-text co-training. The proposed method is evaluated on both in-house and public abdominal CT
      datasets under organ and tumor segmentation tasks. Empirical results
      suggest that the proposed design improves the segmentation performance
      of a baseline model on newly-introduced and previously-learned classes
      along the learning trajectory.
    bibtex: |
      @inproceedings{doe2025superres,
        title={Deep Learning for Image Super-Resolution},
        author={Doe, Jane and Smith, John},
        booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
        year={2025}
      }
    code: https://github.com/janedoe/super-res
    image: ./assets/img/teaser_example.png

  - title: "Mnemonics Training: Multi-Class Incremental Learning without Forgetting"
    authors: <strong>Yaoyao Liu</strong>, Yuting Su, An-An Liu, Bernt Schiele, Qianru Sun
    conference_short: CVPR
    conference: IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, 2020.
    abstract: >
      @inproceedings{liu2020mnemonics,
          author={Liu, Yaoyao and Su, Yuting and Liu, An{-}An and Schiele, Bernt and Sun, Qianru},
          title={Mnemonics Training: Multi-Class Incremental Learning without Forgetting},
          booktitle={The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
          pages={12245--12254},
          year={2020}
    pdf: https://arxiv.org/pdf/2002.10211.pdf
    code: https://github.com/yaoyao-liu/class-incremental-learning/tree/main/mnemonics-training
    bibtex: |
      @inproceedings{liu2020mnemonics,
        author={Liu, Yaoyao and Su, Yuting and Liu, An{-}An and Schiele, Bernt and Sun, Qianru},
        title={Mnemonics Training: Multi-Class Incremental Learning without Forgetting},
        booktitle={The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
        pages={12245--12254},
        year={2020}
      }
    notes: Oral Presentation
    image: ./assets/img/teaser_example_2.png
